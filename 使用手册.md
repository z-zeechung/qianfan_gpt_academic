#### <font color="red">GPT输出的信息往往是不准确的。当涉及学术、医药、法律等领域时，切勿将GPT作为唯一信息源。</font>

#### <font color="red">目前，学界对GPT在学术研究中的使用存在争议，在学术文章中使用GPT，存在受到攻讦的风险，请慎重使用。</font>

### 功能

+ 基本的大语言模型对话功能，包括闲聊、知识查询、写作、翻译、绘制思维导图、角色扮演等。

+ 学术文本的摘要、总结、阐释、翻译、勘误等。

+ PDF文档全文总结、PDF文档全文理解与问答、PDF文档全文翻译。

+ Word文档全文总结。

+ 联网并根据搜索引擎上的结果回答问题。

软件基于开源项目[gpt_academic](https://github.com/binary-husky/gpt_academic)封装，GPT接口来自[百度千帆大模型平台](https://cloud.baidu.com/product/wenxinworkshop)。

由于没时间进行详尽的测试，目前不保证所有功能都能稳定使用。出了问题可以找我修复。

鉴于为[gpt_academic](https://github.com/binary-husky/gpt_academic)开发插件十分容易，如果需要什么特色功能也可以直接找我定制。

### 界面

![](C:\Users\17267\AppData\Roaming\marktext\images\2024-03-01-13-15-36-image.png)

### 开始使用

1. 点击”聊天机器人-学术版.exe“启动程序，等待程序加载好后弹出浏览器。
   
   ![](C:\Users\17267\AppData\Roaming\marktext\images\2024-03-01-13-53-25-image.png)

2. 点击界面左上角的”更换模型“，在选项卡中输入账户和密码
   
   ![](C:\Users\17267\AppData\Roaming\marktext\images\2024-03-01-13-55-17-image.png)
   
   ![](C:\Users\17267\AppData\Roaming\marktext\images\2024-03-01-13-56-45-image.png)

3. 开始使用！在输入区输入你想问的问题，点击”提交“，即可与机器人对话。
   
   ![](C:\Users\17267\AppData\Roaming\marktext\images\2024-03-01-13-58-48-image.png)

4. 如果需要调整页面大小，可以点击右上角的按钮。也可以按住ctrl键后上下滚动鼠标滚轮。
   
   ![](C:\Users\17267\AppData\Roaming\marktext\images\2024-03-04-18-57-53-image.png)

### 资费列表

<table style="table-layout: auto;"><colgroup><col><col style="width: 120px;"><col style="width: 120px;"><col><col style="width: 200px;"><col style="width: 155px;"><col style="width: 90px;"></colgroup><thead class="acud-table-thead"><tr><th class="acud-table-cell">服务名称</th><th class="acud-table-cell">状态</th><th class="acud-table-cell">服务类型</th><th class="acud-table-cell">付费描述</th><th class="acud-table-cell">价格</th><th class="acud-table-cell">开通时间</th><th class="acud-table-cell">操作</th></tr></thead><tbody class="acud-table-tbody"><tr data-row-key="1306" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">ERNIE-Bot 4.0大模型公有云在线调用服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">ERNIE-Bot 4.0模型服务调用时输入、输出token分别计费</td><td class="acud-table-cell"><div class="discont-price"><div>输入：</div><div class="discont-price price-item"><span><span style="color: red;">¥0.12</span>元/千tokens</span><span class="original">¥0.15元/千tokens</span></div></div><div class="discont-price"><div>输出：</div><div class="discont-price price-item"><span><span style="color: red;">¥0.12</span>元/千tokens</span><span class="original">¥0.3元/千tokens</span></div></div></td><td class="acud-table-cell">2024-02-25 16:14:58</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1191" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">ERNIE-Bot大模型公有云在线调用服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">ERNIE-Bot模型服务调用时应用此计费项</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.012元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:14:54</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1219" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">ERNIE-Bot-turbo-0922大模型公有云在线调用服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">ERNIE-Bot-turbo模型服务调用时应用此计费项</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.008元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:14:54</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1378" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">ERNIE-Speed大模型公有云在线调用服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">ERNIE-Speed模型服务调用时输入、输出token分别计费</td><td class="acud-table-cell"><div class="discont-price"><div>输入：</div><div class="discont-price price-item"><span><span style="color: red;">¥0.004</span>元/千tokens</span></div></div><div class="discont-price"><div>输出：</div><div class="discont-price price-item"><span><span style="color: red;">¥0.008</span>元/千tokens</span></div></div></td><td class="acud-table-cell">2024-02-25 16:15:01</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1230" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">BLOOMZ-7B大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">BLOOMZ-7B模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.004元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:14:55</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1268" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">Llama-2-7B-Chat大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">Llama-2-7B-Chat模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.004元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:14:55</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1269" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">Llama-2-13B-Chat大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">Llama-2-13B-Chat模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.006元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:14:55</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1270" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">Llama-2-70B-Chat大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">Llama-2-70B-Chat模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.035元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:14:56</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1271" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">Qianfan-BLOOMZ-7B-compressed大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">Qianfan-BLOOMZ-7B-compressed模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.004元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:14:56</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1272" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">Qianfan-Chinese-Llama-2-7B大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">Qianfan-Chinese-Llama-2-7B模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.004元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:14:56</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1273" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">ChatGLM2-6B-32K大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">ChatGLM2-6B-32K模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.004元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:14:57</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1274" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">AquilaChat-7B大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">AquilaChat-7B模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.004元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:14:57</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1318" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">ERNIE-Bot-8k大模型公有云在线调用服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">ERNIE-Bot-8k模型服务调用时输入、输出token分别计费</td><td class="acud-table-cell"><div class="discont-price"><div>输入：</div><div class="discont-price price-item"><span><span style="color: red;">¥0.024</span>元/千tokens</span></div></div><div class="discont-price"><div>输出：</div><div class="discont-price price-item"><span><span style="color: red;">¥0.048</span>元/千tokens</span></div></div></td><td class="acud-table-cell">2024-02-25 16:14:58</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1359" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">Qianfan-Chinese-Llama-2-13B大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">Qianfan-Chinese-Llama-2-13B模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.006元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:14:59</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1361" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">CodeLlama-7B-Instruct大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">CodeLlama-7B-Instruct模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.004元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:15:00</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1362" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">XuanYuan-70B-Chat-4bit大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">XuanYuan-70B-Chat-4bit模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.035元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:15:00</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1363" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">Yi-34B-Chat</td><td class="acud-table-cell"><div class="status normal"><div>免费使用</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">Yi-34B-Chat模型服务体验时应用此计费项，平台提供算力支持（限时免费）</td><td class="acud-table-cell">-</td><td class="acud-table-cell">-</td><td class="acud-table-cell">无需开通</td></tr><tr data-row-key="1390" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">Mixtral-8x7B-Instruct大模型公有云在线调用体验服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">Mixtral-8x7B-Instruct模型服务体验时应用此计费项，平台提供算力支持</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.035元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:15:01</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1421" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">ERNIE-3.5-4K-0205大模型公有云在线调用服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">ERNIE-3.5-4K-0205模型服务调用时应用此计费项</td><td class="acud-table-cell"><span class="price" style="color: red;">¥0.012元/千tokens</span></td><td class="acud-table-cell">2024-02-25 16:15:01</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr><tr data-row-key="1422" class="acud-table-row acud-table-row-level-0"><td class="acud-table-cell">ERNIE-3.5-8K-0205大模型公有云在线调用服务</td><td class="acud-table-cell"><div class="status normal"><div>付费使用中</div></div></td><td class="acud-table-cell">预置服务</td><td class="acud-table-cell">ERNIE-3.5-8K-0205模型服务调用时输入、输出token分别计费</td><td class="acud-table-cell"><div class="discont-price"><div>输入：</div><div class="discont-price price-item"><span><span style="color: red;">¥0.024</span>元/千tokens</span></div></div><div class="discont-price"><div>输出：</div><div class="discont-price price-item"><span><span style="color: red;">¥0.048</span>元/千tokens</span></div></div></td><td class="acud-table-cell">2024-02-25 16:15:03</td><td class="acud-table-cell"> <a class="table-action">终止付费</a></td></tr></tbody></table>

### 模型概述

<table>
<thead>
<tr>
<th>模型</th>
<th>介绍</th>
<th>支持的API</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ERNIE-Bot 4.0</strong></td>
<td>ERNIE-Bot 4.0是百度自行研发的大语言模型，覆盖海量中文数据，具有更强的对话问答、内容创作生成等能力。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/clntwmv7t" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ERNIE-Bot-8K</strong></td>
<td>百度⾃⾏研发的⼤语⾔模型，覆盖海量中⽂数据，具有更强的对话问答、内容创作⽣成等能⼒，支持5K输入+2K输出。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/6lp69is2a" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ERNIE-Bot</strong></td>
<td>ERNIE-Bot是百度自行研发的大语言模型，覆盖海量中文数据，具有更强的对话问答、内容创作生成等能力。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/jlil56u11" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ERNIE-3.5-4K-0205</strong></td>
<td>ERNIE-3.5-4K-0205是百度自行研发的大语言模型，覆盖海量中文数据，具有更强的对话问答、内容创作生成等能力。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Llsr67q8h" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ERNIE-3.5-8K-0205</strong></td>
<td>ERNIE-3.5-8K-0205是百度自行研发的大语言模型，覆盖海量中文数据，具有更强的对话问答、内容创作生成等能力。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/llsr6hjxo" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ERNIE-3.5-8K-1222</strong></td>
<td>百度⾃⾏研发的⼤语⾔模型，覆盖海量中⽂数据，具有更强的对话问答、内容创作⽣成等能⼒，支持5K输入+2K输出。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/mlt3vdi2j" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ERNIE-Speed</strong></td>
<td>百度自主研发的高效语言模型，基于海量高质数据训练，具有更强的文本理解、内容创作、对话问答等能力</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/klqx7b1xf" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ERNIE-Bot-turbo</strong></td>
<td>ERNIE-Bot-turbo是百度自行研发的大语言模型，覆盖海量中文数据，具有更强的对话问答、内容创作生成等能力，响应速度更快。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/4lilb2lpf" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>EB-turbo-AppBuilder专用版</strong></td>
<td>模型基于ERNIE-Bot-turbo，针对企业级智能客服、内容创作、知识问答等多个任务进行了场景效果和输出格式的优化，可在<a href="https://login.bce.baidu.com/?redirect=https%3A%2F%2Fconsole.bce.baidu.com%2Fai_apaas%2Fapp" target="_blank" rel="nofollow noopener noreferrer">千帆AI原生应用工作台</a>进行开发应用调试。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Alp0kdm0n" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Yi-34B-Chat</strong></td>
<td>由零一万物开发并开源的双语大语言模型，使用4K序列长度进行训练，在推理期间可扩展到32K；模型在多项评测中全球领跑，取得了多项 SOTA 国际最佳性能指标表现，该版本为支持对话的chat版本。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/vlpteyv3c" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>BLOOMZ-7B</strong></td>
<td>BLOOMZ-7B是业内知名的大语言模型，由BigScience研发并开源，能够以46种语言和13种编程语言输出文本。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Jljcadglj" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Qianfan-BLOOMZ-7B-compressed</strong></td>
<td>千帆团队在BLOOMZ-7B基础上的压缩版本，融合量化、稀疏化等技术，显存占用降低30%以上。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/nllyzpcmp" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Mixtral-8x7B-Instruct</strong></td>
<td>由Mistral AI发布的首个高质量稀疏专家混合模型 (MOE)，模型由8个70亿参数专家模型组成，在多个基准测试中表现优于Llama-2-70B及GPT3.5，能够处理32K上下文，在代码生成任务中表现尤为优异。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Rlqx7c834" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Mistral-7B-Instruct</strong></td>
<td>由Mistral AI研发并开源的7B参数大语言模型，具备强大的推理性能和效果，对硬件需求更少、在各项评测基准中超越同规模模型。该版本为Mistral-7B-v0.1基础上的微调版本。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/0lnu3sxhm" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Llama-2-7b-chat</strong></td>
<td>Llama-2-7b-chat由Meta AI研发并开源，在编码、推理及知识应用等场景表现优秀，Llama-2-7b-chat是高性能原生开源版本，适用于对话场景。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Rlki1zlai" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Llama-2-13b-chat</strong></td>
<td>Llama-2-13b-chat由Meta AI研发并开源，在编码、推理及知识应用等场景表现优秀，Llama-2-13b-chat是性能与效果均衡的原生开源版本，适用于对话场景。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/2lki2us1e" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Llama-2-70b-chat</strong></td>
<td>Llama-2-70b-chat由Meta AI研发并开源，在编码、推理及知识应用等场景表现优秀，Llama-2-70b-chat是高精度效果的原生开源版本。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/8lkjfhiyt" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Qianfan-Chinese-Llama-2-7B</strong></td>
<td>千帆团队在Llama-2-7b基础上的中文增强版本，在CMMLU、C-EVAL等中文数据集上表现优异。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Sllyztytp" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Qianfan-Chinese-Llama-2-7B-32K</strong></td>
<td>千帆团队在Qianfan-Chinese-Llama-2-7B基础上的增强版本，支持32K上下文。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Wlrimb8aw" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Qianfan-Chinese-Llama-2-13B</strong></td>
<td>千帆团队在Llama-2-13b基础上的中文增强版本，在CMMLU、C-EVAL等中文数据集上表现优异。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/8lo479b4b" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Qianfan-Llama-2-70B-compressed</strong></td>
<td>是千帆团队在Llama-2-70B基础上的压缩版本，融合量化、稀疏化、算子优化等压缩加速技术，大幅降低模型推理资源占用。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/floqj7kuh" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Linly-Chinese-LLaMA-2-7B</strong></td>
<td>由深圳大学CV研究所Linly项目进行中文增强训练的Llama-2 7b参数版本。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/qlkqu3j29" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Linly-Chinese-LLaMA-2-13B</strong></td>
<td>由深圳大学CV研究所Linly项目进行中文增强训练的Llama-2 13b参数版本。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/ulkqu7kvl" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ChatGLM3-6B</strong></td>
<td>智谱AI与清华KEG实验室发布的中英双语对话模型，相比前两代，具备更强大的基础模型，同时原生支持工具调用（Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Wloqvw3iq" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ChatGLM2-6B</strong></td>
<td>智谱AI与清华KEG实验室发布的中英双语对话模型，具备强大的推理性能、效果、较低的部署门槛及更长的上下文，在MMLU、CEval等数据集上相比初代有大幅的性能提升。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/ilkqu9pib" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ChatGLM2-6B-32K</strong></td>
<td>在ChatGLM2-6B的基础上进一步强化了对于长文本的理解能力，能够更好的处理最多32K长度的上下文。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Bllz001ff" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ChatGLM2-6B-INT4</strong></td>
<td>在ChatGLM2-6B的基础上进行INT4 量化，6G 显存支持的对话长度由 1K 提升到了 8K。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/sllz01g72" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Baichuan2-7B-Chat</strong></td>
<td>是百川智能推出的新一代开源大语言模型，采用2.6万亿Tokens的高质量语料训练，在权威的中文和英文 benchmark 上均取得同尺寸领先的效果。该版本为70亿参数规模的Chat版本。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/nloqvxnp0" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Baichuan2-13B-Chat</strong></td>
<td>Baichuan 2 是百川智能推出的新一代开源大语言模型，采用2.6万亿Tokens的高质量语料训练，在权威的中文和英文 benchmark 上均取得同尺寸领先的效果。该版本为130亿参数规模的Chat版本。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/jlofcjru7" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>XVERSE-13B-Chat</strong></td>
<td>XVERSE-13B-Chat是由深圳元象科技自主研发的支持多语言的大语言模型，支持8k上下文、40多种语言，具备训练效率高、稳定性强、算力利用率高等特点。该版本为130亿参数规模的Chat版本。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Dloff2783" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>XuanYuan-70B-Chat-4bit</strong></td>
<td>由度小满开发，基于Llama2-70B模型进行中文增强的金融行业大模型，通用能力显著提升，在CMMLU/CEVAL等各项榜单中排名前列；金融域任务超越领先通用模型，支持金融知识问答、金融计算、金融分析等各项任务。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Ylp88e5jc" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>DISC-MedLLM</strong></td>
<td>DISC-MedLLM是一个专门针对医疗健康对话式场景而设计的医疗领域大模型，由复旦大学数据智能与社会计算实验室 (Fudan-DISC)开发并开源。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/jloqvyssc" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>ChatLaw</strong></td>
<td>由壹万卷公司与北大深研院研发的法律行业大模型，在开源版本基础上进行了进一步架构升级，融入了法律意图识别、法律关键词提取、CoT推理增强等模块，实现了效果提升，以满足法律问答、法条检索等应用需求。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Qlphtigbf" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Falcon-7B</strong></td>
<td>由TII研发、在精选语料库增强的1500B tokens上进行训练。由OpenBuddy调优并开源，提升了处理复杂对话任务的能力与表现。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/nlkqulm5g" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Falcon-40B-Instruct</strong></td>
<td>由TII研发的仅使用解码器的模型，并在Baize的混合数据集上进行微调，具备优异的推理效果。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Ulkquqcwq" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>AquilaChat-7B</strong></td>
<td>由智源研究院研发，基于Aquila-7B训练的对话模型，支持流畅的文本对话及多种语言类生成任务，通过定义可扩展的特殊指令规范，实现 AquilaChat对其它模型和工具的调用，且易于扩展。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/ollz02e7i" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>RWKV-4-World</strong></td>
<td>由香港大学物理系校友彭博研发并开源，结合了Transformer与RNN的优点，具备优秀的推理性能与效果。RWKV-4-World在100多种语言上进行训练，具备优秀的英语零样本与上下文学习能力。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/plkque69d" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>RWKV-4-pile-14B</strong></td>
<td>由香港大学物理系校友彭博研发并开源，结合了Transformer与RNN的优点，具备优秀的推理性能与效果。RWKV-4-pile-14B为在 Pile 数据集上训练的 L40-D5120 因果语言模型。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Rlkqufn6w" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>RWKV-Raven-14B</strong></td>
<td>由香港大学物理系校友彭博研发并开源，结合了Transformer与RNN的优点，具备优秀的推理性能与效果。RWKV-Raven-14B为在Pile数据集上训练，并在Alpaca、CodeAlpaca等上进行微调的Chat版本。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/ylkqujafk" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>OpenLLaMA-7B</strong></td>
<td>在Meta AI研发的Llama模型基础上，OpenBuddy进行调优，涵盖了更广泛的词汇、通用字符与token嵌入，具备与Llama相当的性能与推理效果。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Ylkquk74n" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>Dolly-12B</strong></td>
<td>由Databricks训练的指令遵循大语言模型。基于pythia-12b，由InstructGPT论文的能力域中生成的约15k指令/响应微调记录训练。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/clkquqy0d" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>MPT-7B-Instruct</strong></td>
<td>MPT-7B-Instruct是一种短格式指令遵循模型，由MosaicML研发，基于MPT-7B模型在Databricks Dolly-15k、HH-RLHF数据集上调优的版本，采用经过修改的仅使用解码器的transformer架构。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/2lkqurg0f" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>MPT-30B-instruct</strong></td>
<td>MPT-30M-Instruct是一种短格式指令遵循模型，由MosaicML研发，基于MPT-7B模型在更为丰富的数据集上调优的版本，采用经过修改的仅使用解码器的transformer架构。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Elkqus29q" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
<tr>
<td><strong>OA-Pythia-12B-SFT-4</strong></td>
<td>基于Pythia12B，Open-Assistant项目的第4次SFT迭代模型。该模型在<code class="language-text">https://open-assistant.io/</code>收集的人类反馈的对话数据上进行微调。</td>
<td><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Ulkqv6tvr" target="_blank" rel="nofollow noopener noreferrer">创建chat</a>，用于发起一次对话请求。</td>
</tr>
</tbody>
</table>
